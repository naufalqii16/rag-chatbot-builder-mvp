# ğŸ¤– RAG Chatbot MVP

A lightweight web-based Retrieval-Augmented Generation (RAG) system that allows users to upload documents (PDF, Excel, CSV, TXT) and instantly chat with an AI chatbot powered by the uploaded knowledge.

---

## ğŸ§  Overview

This project demonstrates how to build a customizable RAG pipeline using **Streamlit**, **LlamaIndex**, and **Qdrant**.  
Each module is organized for easy development, testing, and deployment.

Users can:
- Upload their own knowledge files (finance data, SOP documents, etc.)
- Automatically chunk and embed the text
- Store embeddings in a vector database
- Chat with an AI model that retrieves context-aware answers from the data

---
## âš™ï¸ Tech Stack

This project is built using a modern **AI + Web stack** to create a flexible **Retrieval-Augmented Generation (RAG)** system and deploy a chatbot accessible through the web.

---

### ğŸ§  Core AI Frameworks

- **LangChain** â€” Framework to build and manage LLM-based applications (prompt templates, chains, agents, and retrieval).  
- **LlamaIndex** â€” Simplifies RAG implementation by connecting data sources to the language model.  
- **Groq API** â€” Provides ultra-fast LLM inference compatible with OpenAI format (e.g., Mixtral, Llama-3 models).  
- **Tiktoken** â€” Handles token counting for text chunking and embedding efficiency.

---

### ğŸ’¾ Vector Database

- **Qdrant** â€” Open-source and cloud-ready vector database for storing and retrieving document embeddings efficiently.

---

### ğŸŒ Web Frameworks

- **FastAPI** â€” Backend API framework used to serve the RAG pipeline and handle chat requests.  
- **Streamlit** â€” Lightweight front-end framework for building an interactive chatbot interface.

---

### ğŸ§© Utilities & Data Processing

- **Pandas** â€” Handles structured data input such as Excel or CSV files.  
- **PyPDF** â€” Extracts and processes text from PDF documents.  
- **Requests** â€” Handles API calls and integrations between components.  
- **Pydantic** â€” Ensures clean and validated data models for FastAPI.

---

### ğŸ” Configuration & Environment

- **Python-dotenv** â€” Manages API keys and environment variables through `.env` files.  
- **Uvicorn** â€” ASGI server to run FastAPI in development or production environments.  

---

### ğŸ§± Development & Version Control

- **Virtual Environment (`myvenv/`)** â€” Keeps dependencies isolated per project.  
- **Git & GitHub** â€” Used for version control, code collaboration, and project tracking.

---

### ğŸ§© System Overview

This project enables users to:
1. Upload and index knowledge sources (e.g., PDF or Excel).  
2. Configure chunking parameters and embedding storage in Qdrant.  
3. Interact with an LLM-powered chatbot connected to the indexed data via RAG.


---
## ğŸ“ Folder & File Descriptions

### **Root Directory**

| File | Description |
|------|--------------|
| **.env** | Contains environment variables such as API keys and database URLs. Keep this file private â€” never commit it to Git. |
| **.gitignore** | Lists files and directories that Git should ignore (e.g., `.env`, cache folders). |
| **exploration.ipynb** | Used for quick testing or experimentation (data ingestion, embeddings, etc.) before integrating into the main code. |
| **README.md** | Main documentation file for setup, usage, and structure. |
| **requirements.txt** | Lists all Python dependencies required to run the project. |

---

### **data/**
Stores all uploaded or sample datasets for RAG testing (e.g., Excel, PDF, CSV files).

### **src/**
Main source code directory containing modular components of the RAG pipeline.

#### **config/**
- **`settings.py`**  
  Loads configuration from `.env` (API keys, embedding model, vector DB URL).  
  Centralized configuration ensures consistent access across modules.

---

#### **ingestion/**
Handles reading and preprocessing of documents.

- **`load_files.py`** â€” Reads multiple file formats (PDF, Excel, CSV, TXT) and converts them into plain text.  
- **`chunk_text.py`** â€” Splits text into smaller overlapping chunks for vectorization and retrieval.

---

#### **vectorstore/**
Manages embedding generation and storage in the vector database.

- **`qdrant_client.py`** â€” Connects to the Qdrant instance (local or cloud) and performs CRUD operations.  
- **`index_builder.py`** â€” Converts text chunks into embeddings and stores them in Qdrant for retrieval.

---

#### **rag/**
Implements the RAG pipeline.

- **`retriever.py`** â€” Retrieves the most relevant text chunks from the vector database using semantic similarity.  
- **`query_engine.py`** â€” Combines retrieved context with user queries and sends them to the LLM for final response generation.

---

#### **ui/**
Streamlit interface for user interaction.

- **`app.py`** â€” Main entry point for the web app.  
  Provides file upload, indexing, and chat interface.


---

## âš™ï¸ How It Works

1. **Upload Knowledge** â€” User uploads one or more files (PDF, Excel, etc.) via Streamlit UI.  
2. **Text Extraction & Chunking** â€” The system converts the files to text and splits them into small chunks.  
3. **Embedding & Storage** â€” Each chunk is embedded and stored in the Qdrant vector database.  
4. **User Query** â€” User enters a question in the chatbot interface.  
5. **Context Retrieval** â€” The system retrieves top relevant chunks from Qdrant.  
6. **Answer Generation** â€” The retrieved context is combined with the question and passed to the LLM to generate a response.

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/rag-chatbot-mvp.git
cd rag-chatbot-mvp
```

### 2ï¸âƒ£ Create a Virtual Environment

```bash
python -m venv myvenv
source myvenv/bin/activate     # macOS/Linux
myvenv\Scripts\activate        # Windows
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Environment Variables
Create a `.env` file in the project root:
```bash
OPENAI_API_KEY=your_api_key_here
QDRANT_URL=https://your-qdrant-instance
GROQ_API_KEY=your_api_key_here
```

### 5ï¸âƒ£ Run the App

```bash
streamlit run src/ui/app.py
```